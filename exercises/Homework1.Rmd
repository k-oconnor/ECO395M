---
title: "Homework1"
author: "Kevin O'Connor"
date: "2/9/2022"
output: md_document
---


```{r Loading Libraries, message=FALSE, warning=FALSE}

library(tidyverse)
library(mosaic)
library(ggplot2)
library(dplyr)
library(stringr)
library(modelr)
library(rsample)
library(caret)
library(parallel)
library(foreach)
library(knitr)
```


# Problem 1
```{r Problem 1a, message=FALSE, warning=FALSE}
ABIA <- read_csv("ABIA.csv")

ABIA_Adjust = ABIA%>% select(UniqueCarrier,ArrDelay,Origin)

ABIA_Adjust = na.omit(ABIA_Adjust)

mean_table =ABIA_Adjust %>%
dplyr::filter(str_detect(Origin,"AUS"))%>%
  group_by(UniqueCarrier) %>%
  summarize(mean_delay = mean(ArrDelay))

mean_table %>% ggplot(aes(fct_reorder(UniqueCarrier,mean_delay),mean_delay)) + geom_col(fill="steelblue") + coord_flip() + labs(y= "Average Time Late on Arrival(min)", x="Airline", title = "Departing Austin: Which Airline is Most Late on Average")+theme_linedraw()

include_graphics(Homework1_files/figure-markdown_strict/Problem%201a-1.png)
```

Imagine you are the most sensitive person to having your time wasted in Austin. Every flight you take feels like a torturous lottery. You may wonder which airlines are more likely to be on time. As we see in the above naive plot, some airlines appear truly later than others. Particularly, Delta and PSA Airlines. Is it fair to make this judgement? Perhaps there are other factors influencing the distribution. For example, maybe some airlines are far more likely to travel longer distances, and thereby lose more time on the longer flights due to factors such as prevailing winds on a particular long route.


```{r Problem 1b, message=FALSE, warning=FALSE}
ABIA_Adjust = ABIA%>% select(UniqueCarrier,ArrDelay,Origin,Dest,Month)

ABIA_Adjust = na.omit(ABIA_Adjust)

mean_table =ABIA_Adjust %>%
dplyr::filter(str_detect(Origin,"AUS"))%>%
  group_by(UniqueCarrier,Month) %>%
  summarize(mean_delay = mean(ArrDelay))

mean_table %>% ggplot(aes(x=UniqueCarrier, y=mean_delay, group=Month)) + geom_boxplot()+ylim (1,40)
```

A possibly more honest way to look at the data would be to plot the distributions of average late arrivals over the months. From this view, we can see that even with relatively low averages, some airlines have far more variability in their arrival times. From the previous graph, one might consider United Airlines (UA) as a reliable choice. However, United has some of the most extreme variation in late arrival times. This may be a better view of consistency.

# Problem 2
## Part A:
```{r Problem 2a, message=FALSE, warning=FALSE}
billboard <- read_csv("billboard.csv")

billboard_ct = billboard %>%
mutate(count = weeks_on_chart)

billboard_c <- billboard %>% group_by(performer,song) %>%
mutate(count = max(weeks_on_chart)) %>%
arrange(desc(count))

billboard_cd <- billboard_c %>%
select(performer, song, count)

billboard_ce <- unique(billboard_cd)

top_ten <- billboard_ce[1:10,]
print(top_ten)
```

We are tasked with making a table of the 10 most popular songs measured by the total number of weeks the song appeared in the billboard "Top 100" list. We observe that some newer songs from the early 2010s and 2000s are some of the most popular of all time. Imagine Dragons' smash hit "Radioactive", with almost two years of being on the top 100 is a clear standout winner.

## Part B:
```{r Problem 2b, message=FALSE, warning=FALSE}
billboard_u <- billboard %>%
select(year,song)

billboard_u = unique(billboard_u)

spy <- billboard_u %>% count(year)


spy_adjust = spy %>% slice(-c(1,64))
year = spy_adjust$year
number_of_songs = spy_adjust$n

ggplot(data = spy_adjust) + geom_line(aes(x= year,y=number_of_songs), color = "steelblue",size =2) + labs(y= "Number of Unique Songs", x="Year", title = "Musical Diversity on the Billboard Top 100") +theme_linedraw()
```

In this figure, we are measuring musical diversity defined as the number of unique songs to appear on the Billboard "Top 100" list over the course of a given year. We omitted 1958 and 2021 from this figure, as the data for these two years is incomplete. We observe that musical diversity steadily declined from the 60's onward into the 2000s. In 2004, musical diversity began to rebound to where music is almost as diverse in the 2020s as in the measures all time high in the mid 1960s.
## Part C:
```{r Problem 2c, message=FALSE, warning=FALSE}
twh = billboard_ce %>%
mutate(ten_week_hit = ifelse(count >= 10, yes=1, no =0))

ten_week_hit = twh$ten_week_hit
performer = twh$performer

twhl = twh[!(twh$ten_week_hit=="0"),] %>%
group_by(performer)%>%
count(ten_week_hit)%>%
arrange(desc(n))
final_list = twhl[1:19,] %>% select(performer,n)

performer = final_list$performer
number_of_ten_week_hits = final_list$n


final_list %>% ggplot(aes(fct_reorder(performer,number_of_ten_week_hits),number_of_ten_week_hits)) + geom_col(fill="steelblue") + coord_flip() + labs(y= "Number of Ten Week Hits", x="Performing Artist", title = "Artists With the Most Ten Week Hits")+theme_linedraw()
```

In this figure, we are dialing in on major hits that were on the Billboard "Top 100" list for at least 10 weeks, which we will refer to as "Ten Week Hits", and the artists that performed them. Some artists have been astonishingly successful at making many chart topping hits. We observe 19 artists with at least 30 "Ten Week Hits". Elton John is the most successful of all time, with a mind boggling 53 "Ten Week Hits".
# Problem 3
## Part A:
```{r Problem 3a, message=FALSE, warning=FALSE}
olympics_top20 <- read_csv("olympics_top20.csv")

q95 <- olympics_top20 %>%
filter(str_detect(sex,"F")) %>%
group_by(event) %>%
summarize(Height_at_95th_Quantile = quantile(height, prob =(.95)))
print(q95)
```

How does height vary across all of the women's olympic events? In the above table, we show what height at the 95th quantile is for each of the 132 women's olympic events in centimeters. Unsurprisingly, the tallest women at the 95th quantile are Women's Basketball players, with a 95th quantile height of 197.55 cm.
## Part B:
```{r Problem 3b, message=FALSE, warning=FALSE}
wsd <- olympics_top20 %>%
filter(str_detect(sex,"F")) %>%
group_by(event) %>%
summarize(Standard_Deviation_Height = sd(height))%>%
arrange(desc(Standard_Deviation_Height))
print(wsd[1,])
```

In which women's Olympic event is the variation in height the greatest? We would expect that it would be an event where height doesn't provide much of a meaningful advantage, and what we would expect is evidently true. In "Rowing Women's Coxed Fours", the standard deviation of height is 10.865 cm.

## Part C:
```{r Problem 3c, message=FALSE, warning=FALSE}
swm <- olympics_top20 %>%
filter(str_detect(sport, "Swimming")) %>%
group_by(year, sex) %>%
summarize(age = mean(age))

swm%>%
ggplot() + geom_line(aes(x=year, y=age, group =sex, color = sex),size =2) + labs(y= "Athlete Age", x="Year", title = "Average Age of Olympic Swimmers") +theme_linedraw()
```

How has the average age of Olympic swimmers changed over the years? For men, we initially observe that swimmers were extremely young, at 18 years old. The average age rose sharply into the 1920s before sharply declining to 19 years of age, and stabilizing around 20 years old until the late 1970s. Since the 1970s, age has been steadily increasing to the mid 20s. Woman swimmers were allowed to participate in the games starting in the 1920s. Women swimmers on average have been roughly two years younger than their male counterparts.The overall trend however has been similar. In the mid to late 1970s, the average age of women swimmers began to steadily increase from younger than 18 to 22 years of age into the 2000s.

# Problem 4
## Part A:
```{r Problem 4a, message=FALSE, warning=FALSE}
sclass <- read_csv("sclass.csv")

Three_Fifty = sclass %>%
  filter(trim == 350)
set.seed(23)
split = initial_split(Three_Fifty, prop=.8)
Three_Fifty_train = training(split)
Three_Fifty_test = testing(split)

rmse_out=foreach(k=1:150, .combine='rbind')%do%{


knn_model = knnreg(price ~mileage, data = Three_Fifty_train, k =k)
modelr::rmse(knn_model,Three_Fifty_test)
} %>% as.data.frame
rmse_out

row_adjust = c(1:150)
rownames(rmse_out) = row_adjust
rmse_out$k <- c(1:150) 

ggplot(rmse_out) + geom_line(aes(x=k,y=V1),size =2) + labs(y= "RMSE", x="K", title = "Root Mean Square Error for Different Values of K") +theme_linedraw() + geom_vline(xintercept=67, linetype="dashed", color = "red")

include_graphics()
```

```{r Problem 4b, message=FALSE, warning=FALSE}
knn_model1 = knnreg(price ~mileage, data = Three_Fifty_train, k =67)
Three_Fifty_test= Three_Fifty_test %>%
  mutate(TF_pred = predict(knn_model1,Three_Fifty_test))

Three_Fifty_test %>%
  ggplot() + geom_point(aes(x=mileage, y=price)) + geom_line(aes(x=mileage, y=TF_pred),color = "darkred") + theme_linedraw() +labs(y= "Price", x="Mileage", title = "Predicted Price of Secondhand Mercedes S350")+ scale_x_continuous(labels = scales:: comma)
```

```{r Problem 4c, message=FALSE, warning=FALSE}
Sixty_five_AMG = sclass %>%
  filter(str_detect(trim,"65 AMG"))
set.seed(123)
split = initial_split(Sixty_five_AMG, prop=.8)
Sixty_five_AMG_train = training(split)
Sixty_five_AMG_test = testing(split)

rmse_out=foreach(k=1:150, .combine='rbind')%do%{



knn_model = knnreg(price ~mileage, data = Sixty_five_AMG_train, k =k)
modelr::rmse(knn_model,Sixty_five_AMG_test)
} %>% as.data.frame
rmse_out

row_adjust = c(1:150)
rownames(rmse_out) = row_adjust
rmse_out$k <- c(1:150) 

ggplot(rmse_out) + geom_line(aes(x=k,y=V1),size =2) + labs(y= "RMSE", x="K", title = "Root Mean Square Error for Different Values of K") +theme_linedraw() + geom_vline(xintercept=15, linetype="dashed", color = "red")
```

```{r Problem 4d, message=FALSE, warning=FALSE}
knn_model2 = knnreg(price ~mileage,data = Sixty_five_AMG_train, k =15)
data = Sixty_five_AMG_test= Sixty_five_AMG_test %>%
  mutate(TF_pred = predict(knn_model2,Sixty_five_AMG_test))

Sixty_five_AMG_test %>%
  ggplot() + geom_point(aes(x=mileage, y=price)) + geom_line(aes(x=mileage, y=TF_pred),color = "darkred") + theme_linedraw() +labs(y= "Price", x="Mileage", title = "Predicted Price of Secondhand Mercedes 65 AMG") + scale_x_continuous(labels = scales:: comma)
```

When choosing an optimal value for "K" in KNN models, we have to consider the bias-variance trade off. As K decreases, the variance of the fit tends to increase,and bias decreases. As shown in the RMSE vs. K plots, the optimal value of K varies between the different trim levels of the Mercedes S-Class. For the S350 trim level, we select an optimal K value of 67. For the 65 AMG trim, we select an optimal K of 15.

What is the reason behind the different values of K between the trim levels? I believe that the answer lies in the sizes of the data sets for each trim level. There are 416 observations for the S350 trim, and 292 for the S65 AMG trim. As we are selecting for the lowest RMSE, we would expect the data set with more observations to favor lower variance over bias, as with the higher amount of observations, bias is likely lower to begin with. For the smaller data set, we would expect the converse to be true. We will favor lower bias estimates over higher variance estimates.